{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "spam_csv = pd.read_csv('spamtexts.csv', encoding='latin-1')\n",
    "df = pd.DataFrame(spam_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = 0\n",
    "spam = 1\n",
    "\n",
    "# CREATING NEW COLUMN 'category' TO CATEGORIES HAM=0/SPAM=1\n",
    "# REMOVING OLD COLUMN 'Category'\n",
    "df.insert(1, 'category', 0)\n",
    "df.loc[df['Category'] == 'spam', 'category'] = 1\n",
    "\n",
    "df = df.drop(['Category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOWER-CASING ALL THE TEXT\n",
    "df.message = df.message.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_char_list = []\n",
    "\n",
    "for row in df.message:\n",
    "    for character in row:\n",
    "        if character not in message_char_list:\n",
    "            print(character)\n",
    "            message_char_list.append(character)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message_char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "punctuation = list(string.punctuation)\n",
    "numbers = list(string.digits)\n",
    "whitespace = list(string.whitespace)\n",
    "\n",
    "print(alphabet, punctuation, numbers, whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_char_list = []\n",
    "\n",
    "for x in message_char_list:\n",
    "    if x not in alphabet:\n",
    "        if x not in numbers:\n",
    "            if x not in punctuation:\n",
    "                dirty_char_list.append(x)\n",
    "\n",
    "dirty_char_list.remove(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â', '£', '\\x92', 'ã', 'º', '\\x80', '\\x98', '¼', '\\x9c', '\\x93', '¦', '¨', '\\x94', '\\x91', '\\x99', '\\x96', '»', '©', '\\x89', '¬', '\\r', '\\n', '\\t', 'é', '\\x88', '¥', '¾', '¡']\n"
     ]
    }
   ],
   "source": [
    "print(dirty_char_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan is to create a function that checks to see if character is in the dirty_char_list. \n",
    "* If so it will replace the character depending on what it is.\n",
    "* If it is a number, replace with number \" \",\n",
    "* If it is punctuation, replace with \" \",\n",
    "* Otherwise, replace it with \" \".\n",
    "* Finally replace whitespace where whitespace len > 1, to \" \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df\n",
    "\n",
    "print(df_new.message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dirty_char_list:\n",
    "    df_new.message = df_new.message.str.replace(x, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in punctuation:\n",
    "    df_new.message = df_new.message.str.replace(x, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in numbers:\n",
    "    df_new.message = df_new.message.str.replace(x, 'number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(\"preprocessing_spamtexts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into two new dataframes based on category\n",
    "df_ham, df_spam = [x for _, x in df_new.groupby(df_new.category == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_ham, df_spam)\n",
    "print(len(df_ham), len(df_spam)) #expecting 4825 ham 747 spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = 0:3377\n",
    "# test = 3378:4824\n",
    "df_ham.message.iloc[0:3378].to_csv(\"nonspam_train.csv\", index=False, header=False)\n",
    "\n",
    "df_ham.message.iloc[3379:4824].to_csv(\"nonspam_test.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = 0:523\n",
    "# test = 524:746\n",
    "df_spam.message.iloc[0:523].to_csv(\"spam_train.csv\", index=False, header=False)\n",
    "\n",
    "df_spam.message.iloc[524:746].to_csv(\"spam_test.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for message in df_new.message.str.split(' '):\n",
    "    word_list.extend(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "temp_holder = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_list:\n",
    "    if word in stop_words:\n",
    "        pass\n",
    "    elif word not in temp_holder:\n",
    "        temp_holder.append(word)\n",
    "        word_dict[word] = word_list.count(word)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_dict['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dictionary.txt\", 'w') as f: \n",
    "    for key, value in sorted_dict: \n",
    "        f.write(f'{key} {value}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEXT STEPS**\n",
    "\n",
    "* Load the dictionary file into MATLAB. You can use the readtable function to read in the data and store it in a table object.\n",
    "\n",
    "* Create a bag-of-words model for the text data. You can use the `bagOfWords` function to create a bag-of-words model from the tokenized text. You can pass in the dictionary table as the second argument to the `bagOfWords` function to use the dictionary to create the bag-of-words model. This will create a matrix where each row represents a document and each column represents a word in the dictionary. The values in the matrix will be the number of times the word appears in the document.\n",
    "* Split the data into training and test sets. You can use the cvpartition function to create a random partition of the data into training and test sets.\n",
    "* Train the classifier. You can use the fitcnb function to train a Naive Bayes classifier on the training data.\n",
    "* Test the classifier. You can use the predict function to predict the labels for the test data and compare them to the true labels to evaluate the classifier's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06b0aa4c7316fd05e1fbc35be8f0e5fb9e74ae2fa97553ccced32907b2c022cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
